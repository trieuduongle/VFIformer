{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "id": "Wro-793iCP7w",
        "outputId": "9e9689d7-4956-436a-9282-9ab1f675312b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/My Drive/foo.txt', 'w') as f:\n",
        "  f.write('Hello Google Drive!')\n",
        "!cat /content/drive/My\\ Drive/foo.txt"
      ],
      "metadata": {
        "id": "A12QcaVOCZjl",
        "outputId": "d8c68f8a-2135-49b6-f9cb-752b45b95ed0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello Google Drive!"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/trieuduongle/VFIformer.git '/content/drive/My Drive/Duong/VFIformer/code'"
      ],
      "metadata": {
        "id": "M9Vb0A2-EcvB",
        "outputId": "5c37c39b-40cf-4965-db7a-dedaeef10dfb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path '/content/drive/My Drive/Duong/VFIformer/code' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd '/content/drive/My Drive/Duong/VFIformer/code'"
      ],
      "metadata": {
        "id": "cO72eFDsHF-3",
        "outputId": "78190a45-bf44-4e9b-9423-4ec8d73d542a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/Duong/VFIformer/code\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get update -y && sudo apt-get install python3.9"
      ],
      "metadata": {
        "id": "CiLkHhCBKexJ",
        "outputId": "ad690d17-ba8e-49e9-d93e-5132b3abd3a1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hit:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
            "Hit:2 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Ign:3 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:6 http://security.ubuntu.com/ubuntu bionic-security InRelease\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Hit:9 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:10 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n",
            "Hit:11 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n",
            "Hit:12 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Hit:13 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "python3.9 is already the newest version (3.9.15-1+bionic1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 5 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.9* 3\n",
        "!sudo update-alternatives --config python3"
      ],
      "metadata": {
        "id": "_vCsDMK586ib",
        "outputId": "f9acd0be-1fa4-4b70-b81d-a2c3dfbfd1d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 4 choices for the alternative python3 (providing /usr/bin/python3).\n",
            "\n",
            "  Selection    Path                 Priority   Status\n",
            "------------------------------------------------------------\n",
            "  0            /usr/bin/python3.9    3         auto mode\n",
            "* 1            /usr/bin/python3.10   1         manual mode\n",
            "  2            /usr/bin/python3.6    1         manual mode\n",
            "  3            /usr/bin/python3.7    2         manual mode\n",
            "  4            /usr/bin/python3.9    3         manual mode\n",
            "\n",
            "Press <enter> to keep the current choice[*], or type selection number: 0\n",
            "update-alternatives: using /usr/bin/python3.9 to provide /usr/bin/python3 (python3) in auto mode\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt install python3.9-distutils\n",
        "!python -m pip install --upgrade pip"
      ],
      "metadata": {
        "id": "X5-6wEGr9OSn",
        "outputId": "bfa65b58-70c5-431f-bc9b-893681cff13e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "python3.9-distutils is already the newest version (3.9.15-1+bionic1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 5 not upgraded.\n",
            "Collecting pip\n",
            "  Downloading https://files.pythonhosted.org/packages/09/bd/2410905c76ee14c62baf69e3f4aa780226c1bbfc9485731ad018e35b0cb5/pip-22.3.1-py3-none-any.whl (2.1MB)\n",
            "\u001b[K    100% |████████████████████████████████| 2.1MB 745kB/s \n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Found existing installation: pip 9.0.1\n",
            "    Not uninstalling pip at /usr/lib/python3/dist-packages, outside environment /usr\n",
            "Successfully installed pip-22.3.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.10 1\n",
        "!sudo update-alternatives --config python3\n",
        "!python --version\n",
        "!sudo apt install python3-pip"
      ],
      "metadata": {
        "id": "y9A_FHz3L3Xo",
        "outputId": "128481c6-8369-4f8f-f03e-d3043658745a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 4 choices for the alternative python3 (providing /usr/bin/python3).\n",
            "\n",
            "  Selection    Path                 Priority   Status\n",
            "------------------------------------------------------------\n",
            "* 0            /usr/bin/python3.9    3         auto mode\n",
            "  1            /usr/bin/python3.10   1         manual mode\n",
            "  2            /usr/bin/python3.6    1         manual mode\n",
            "  3            /usr/bin/python3.7    2         manual mode\n",
            "  4            /usr/bin/python3.9    3         manual mode\n",
            "\n",
            "Press <enter> to keep the current choice[*], or type selection number: 0\n",
            "Python 3.9.15\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "python3-pip is already the newest version (9.0.1-2.3~ubuntu1.18.04.5).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 5 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git checkout colab && git pull && pip install -r requirements.txt -f https://download.pytorch.org/whl/cu111/torch_stable.html"
      ],
      "metadata": {
        "id": "IbMoodR4I95F",
        "outputId": "a45db7bd-d3bd-4cf4-bbf0-0badcd0d039c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Already on 'colab'\n",
            "Your branch is up to date with 'origin/colab'.\n",
            "remote: Enumerating objects: 5, done.\u001b[K\n",
            "remote: Counting objects: 100% (5/5), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 3 (delta 2), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (3/3), done.\n",
            "From https://github.com/trieuduongle/VFIformer\n",
            "   cbefb01..12bed71  colab      -> origin/colab\n",
            "Updating cbefb01..12bed71\n",
            "Fast-forward\n",
            " VFIFormer.ipynb | 1289 \u001b[32m+++++++++++++++++++++\u001b[m\u001b[31m----------------------------------\u001b[m\n",
            " 1 file changed, 501 insertions(+), 788 deletions(-)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://download.pytorch.org/whl/cu111/torch_stable.html\n",
            "Collecting matplotlib==3.5.3\n",
            "  Downloading matplotlib-3.5.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 11.2 MB 4.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy==1.21.6 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (1.21.6)\n",
            "Requirement already satisfied: opencv_python==4.6.0.66 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 3)) (4.6.0.66)\n",
            "Collecting Pillow==9.2.0\n",
            "  Downloading Pillow-9.2.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 77.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy==1.7.3 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (1.7.3)\n",
            "Collecting tensorboardX==2.5.1\n",
            "  Downloading tensorboardX-2.5.1-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[K     |████████████████████████████████| 125 kB 92.1 MB/s \n",
            "\u001b[?25hCollecting timm==0.6.7\n",
            "  Downloading timm-0.6.7-py3-none-any.whl (509 kB)\n",
            "\u001b[K     |████████████████████████████████| 509 kB 88.2 MB/s \n",
            "\u001b[?25hCollecting torch==1.8.1+cu111\n",
            "  Downloading https://download.pytorch.org/whl/cu111/torch-1.8.1%2Bcu111-cp37-cp37m-linux_x86_64.whl (1982.2 MB)\n",
            "\u001b[K     |█████████████▌                  | 834.1 MB 1.3 MB/s eta 0:14:57tcmalloc: large alloc 1147494400 bytes == 0x393e8000 @  0x7f718bed4615 0x58ead6 0x4f355e 0x4d222f 0x51041f 0x5b4ee6 0x58ff2e 0x510325 0x5b4ee6 0x58ff2e 0x50d482 0x4d00fb 0x50cb8d 0x4d00fb 0x50cb8d 0x4d00fb 0x50cb8d 0x4bac0a 0x538a76 0x590ae5 0x510280 0x5b4ee6 0x58ff2e 0x50d482 0x5b4ee6 0x58ff2e 0x50c4fc 0x58fd37 0x50ca37 0x5b4ee6 0x58ff2e\n",
            "\u001b[K     |█████████████████               | 1055.7 MB 1.2 MB/s eta 0:13:11tcmalloc: large alloc 1434370048 bytes == 0x7da3e000 @  0x7f718bed4615 0x58ead6 0x4f355e 0x4d222f 0x51041f 0x5b4ee6 0x58ff2e 0x510325 0x5b4ee6 0x58ff2e 0x50d482 0x4d00fb 0x50cb8d 0x4d00fb 0x50cb8d 0x4d00fb 0x50cb8d 0x4bac0a 0x538a76 0x590ae5 0x510280 0x5b4ee6 0x58ff2e 0x50d482 0x5b4ee6 0x58ff2e 0x50c4fc 0x58fd37 0x50ca37 0x5b4ee6 0x58ff2e\n",
            "\u001b[K     |█████████████████████▋          | 1336.2 MB 120.0 MB/s eta 0:00:06tcmalloc: large alloc 1792966656 bytes == 0x2870000 @  0x7f718bed4615 0x58ead6 0x4f355e 0x4d222f 0x51041f 0x5b4ee6 0x58ff2e 0x510325 0x5b4ee6 0x58ff2e 0x50d482 0x4d00fb 0x50cb8d 0x4d00fb 0x50cb8d 0x4d00fb 0x50cb8d 0x4bac0a 0x538a76 0x590ae5 0x510280 0x5b4ee6 0x58ff2e 0x50d482 0x5b4ee6 0x58ff2e 0x50c4fc 0x58fd37 0x50ca37 0x5b4ee6 0x58ff2e\n",
            "\u001b[K     |███████████████████████████▎    | 1691.1 MB 1.1 MB/s eta 0:04:18tcmalloc: large alloc 2241208320 bytes == 0x6d658000 @  0x7f718bed4615 0x58ead6 0x4f355e 0x4d222f 0x51041f 0x5b4ee6 0x58ff2e 0x510325 0x5b4ee6 0x58ff2e 0x50d482 0x4d00fb 0x50cb8d 0x4d00fb 0x50cb8d 0x4d00fb 0x50cb8d 0x4bac0a 0x538a76 0x590ae5 0x510280 0x5b4ee6 0x58ff2e 0x50d482 0x5b4ee6 0x58ff2e 0x50c4fc 0x58fd37 0x50ca37 0x5b4ee6 0x58ff2e\n",
            "\u001b[K     |████████████████████████████████| 1982.2 MB 1.1 MB/s eta 0:00:01tcmalloc: large alloc 1982177280 bytes == 0xf2fba000 @  0x7f718bed31e7 0x4b2590 0x4b261c 0x58ead6 0x4f355e 0x4d222f 0x51041f 0x5b4ee6 0x58ff2e 0x50ca37 0x5b4ee6 0x58ff2e 0x50ca37 0x5b4ee6 0x58ff2e 0x50ca37 0x5b4ee6 0x58ff2e 0x50ca37 0x5b4ee6 0x58ff2e 0x50ca37 0x58fd37 0x50ca37 0x5b4ee6 0x58ff2e 0x50d482 0x5b4ee6 0x58ff2e 0x50d482 0x5b4ee6\n",
            "tcmalloc: large alloc 2477727744 bytes == 0x169214000 @  0x7f718bed4615 0x58ead6 0x4f355e 0x4d222f 0x51041f 0x5b4ee6 0x58ff2e 0x50ca37 0x5b4ee6 0x58ff2e 0x50ca37 0x5b4ee6 0x58ff2e 0x50ca37 0x5b4ee6 0x58ff2e 0x50ca37 0x5b4ee6 0x58ff2e 0x50ca37 0x58fd37 0x50ca37 0x5b4ee6 0x58ff2e 0x50d482 0x5b4ee6 0x58ff2e 0x50d482 0x5b4ee6 0x4bad99 0x4d3249\n",
            "\u001b[K     |████████████████████████████████| 1982.2 MB 3.3 kB/s \n",
            "\u001b[?25hCollecting torchvision==0.9.1+cu111\n",
            "  Downloading https://download.pytorch.org/whl/cu111/torchvision-0.9.1%2Bcu111-cp37-cp37m-linux_x86_64.whl (17.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 17.6 MB 30.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.5.3->-r requirements.txt (line 1)) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.5.3->-r requirements.txt (line 1)) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.5.3->-r requirements.txt (line 1)) (21.3)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.5.3->-r requirements.txt (line 1)) (3.0.9)\n",
            "Collecting fonttools>=4.22.0\n",
            "  Downloading fonttools-4.38.0-py3-none-any.whl (965 kB)\n",
            "\u001b[K     |████████████████████████████████| 965 kB 82.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.5.3->-r requirements.txt (line 1)) (0.11.0)\n",
            "Requirement already satisfied: protobuf<=3.20.1,>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX==2.5.1->-r requirements.txt (line 6)) (3.19.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.1+cu111->-r requirements.txt (line 8)) (4.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7->matplotlib==3.5.3->-r requirements.txt (line 1)) (1.15.0)\n",
            "Installing collected packages: torch, Pillow, torchvision, fonttools, timm, tensorboardX, matplotlib\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.12.1+cu113\n",
            "    Uninstalling torch-1.12.1+cu113:\n",
            "      Successfully uninstalled torch-1.12.1+cu113\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: Pillow 7.1.2\n",
            "    Uninstalling Pillow-7.1.2:\n",
            "      Successfully uninstalled Pillow-7.1.2\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.13.1+cu113\n",
            "    Uninstalling torchvision-0.13.1+cu113:\n",
            "      Successfully uninstalled torchvision-0.13.1+cu113\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.2.2\n",
            "    Uninstalling matplotlib-3.2.2:\n",
            "      Successfully uninstalled matplotlib-3.2.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.13.1 requires torch==1.12.1, but you have torch 1.8.1+cu111 which is incompatible.\n",
            "torchaudio 0.12.1+cu113 requires torch==1.12.1, but you have torch 1.8.1+cu111 which is incompatible.\u001b[0m\n",
            "Successfully installed Pillow-9.2.0 fonttools-4.38.0 matplotlib-3.5.3 tensorboardX-2.5.1 timm-0.6.7 torch-1.8.1+cu111 torchvision-0.9.1+cu111\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -r requirements.txt"
      ],
      "metadata": {
        "id": "syd88yVWQA28"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.cuda.device_count()\n",
        "torch.cuda.is_available()\n",
        "torch.cuda.current_device()\n",
        "torch.cuda.device(0)\n",
        "torch.cuda.get_device_name(0)"
      ],
      "metadata": {
        "id": "xgg3AuNpCryO",
        "outputId": "429ca830-681e-4d16-9c36-5ac84b2bb450",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-65426ad33994>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_device_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36mcurrent_device\u001b[0;34m()\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcurrent_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;34mr\"\"\"Returns the index of a currently selected device.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0m_lazy_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_getDevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;31m# This function throws if there's a driver initialization error, no GPUs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;31m# are found or any other error occurs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: No CUDA GPUs are available"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python compute_flow_vimeo.py"
      ],
      "metadata": {
        "id": "7Dgb-CEeSynO",
        "outputId": "7d024c2e-6f39-4d49-a4ec-1e82c6672e2f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"compute_flow_vimeo.py\", line 16, in <module>\n",
            "    from .correlation import correlation # the custom cost volume layer\n",
            "ImportError: attempted relative import with no known parent package\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/cupy/__init__.py\", line 18, in <module>\n",
            "    from cupy import _core  # NOQA\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/cupy/_core/__init__.py\", line 3, in <module>\n",
            "    from cupy._core import core  # NOQA\n",
            "  File \"cupy/_core/core.pyx\", line 1, in init cupy._core.core\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/cupy/cuda/__init__.py\", line 8, in <module>\n",
            "    from cupy.cuda import compiler  # NOQA\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/cupy/cuda/compiler.py\", line 13, in <module>\n",
            "    from cupy.cuda import device\n",
            "  File \"cupy/cuda/device.pyx\", line 1, in init cupy.cuda.device\n",
            "ImportError: /usr/local/lib/python3.7/dist-packages/cupy_backends/cuda/api/runtime.cpython-37m-x86_64-linux-gnu.so: symbol cudaMemPoolTrimTo version libcudart.so.11.0 not defined in file libcudart.so.11.0 with link time reference\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"compute_flow_vimeo.py\", line 18, in <module>\n",
            "    sys.path.insert(0, './correlation'); import correlation # you should consider upgrading python\n",
            "  File \"./correlation/correlation.py\", line 3, in <module>\n",
            "    import cupy\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/cupy/__init__.py\", line 27, in <module>\n",
            "    ''') from exc\n",
            "ImportError: \n",
            "================================================================\n",
            "Failed to import CuPy.\n",
            "\n",
            "If you installed CuPy via wheels (cupy-cudaXXX or cupy-rocm-X-X), make sure that the package matches with the version of CUDA or ROCm installed.\n",
            "\n",
            "On Linux, you may need to set LD_LIBRARY_PATH environment variable depending on how you installed CUDA/ROCm.\n",
            "On Windows, try setting CUDA_PATH environment variable.\n",
            "\n",
            "Check the Installation Guide for details:\n",
            "  https://docs.cupy.dev/en/latest/install.html\n",
            "\n",
            "Original error:\n",
            "  ImportError: /usr/local/lib/python3.7/dist-packages/cupy_backends/cuda/api/runtime.cpython-37m-x86_64-linux-gnu.so: symbol cudaMemPoolTrimTo version libcudart.so.11.0 not defined in file libcudart.so.11.0 with link time reference\n",
            "================================================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m torch.distributed.launch --nproc_per_node=4 --master_port=4174 train.py --launcher pytorch --gpu_ids 0 \\\n",
        "            --loss_flow --use_tb_logger --batch_size 48 --net_name IFNet --name train_IFNet --max_iter 300 --crop_size 192 --save_epoch_freq 5 \\\n",
        "            --data_root \"/content/drive/My Drive/Duong/datasets/vimeo-small\""
      ],
      "metadata": {
        "id": "dWAMQQfeKyzJ",
        "outputId": "c57e9988-750c-4c04-8af4-65cc82c3157c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/distributed/launch.py:186: FutureWarning: The module torch.distributed.launch is deprecated\n",
            "and will be removed in future. Use torchrun.\n",
            "Note that --use_env is set by default in torchrun.\n",
            "If your script expects `--local_rank` argument to be set, please\n",
            "change it to read from `os.environ['LOCAL_RANK']` instead. See \n",
            "https://pytorch.org/docs/stable/distributed.html#launch-utility for \n",
            "further instructions\n",
            "\n",
            "  FutureWarning,\n",
            "WARNING:torch.distributed.run:\n",
            "*****************************************\n",
            "Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
            "*****************************************\n",
            "Traceback (most recent call last):\n",
            "  File \"train.py\", line 16, in <module>\n",
            "Traceback (most recent call last):\n",
            "  File \"train.py\", line 16, in <module>\n",
            "Traceback (most recent call last):\n",
            "  File \"train.py\", line 16, in <module>\n",
            "Traceback (most recent call last):\n",
            "  File \"train.py\", line 16, in <module>\n",
            "        from models import Trainerfrom models import Trainer\n",
            "\n",
            "      File \"/content/drive/My Drive/Duong/VFIformer/code/models/__init__.py\", line 1, in <module>\n",
            "from models import Trainer  File \"/content/drive/My Drive/Duong/VFIformer/code/models/__init__.py\", line 1, in <module>\n",
            "\n",
            "  File \"/content/drive/My Drive/Duong/VFIformer/code/models/__init__.py\", line 1, in <module>\n",
            "    from models import Trainer\n",
            "  File \"/content/drive/My Drive/Duong/VFIformer/code/models/__init__.py\", line 1, in <module>\n",
            "    from .trainer import Trainer\n",
            "    from .trainer import Trainer  File \"/content/drive/My Drive/Duong/VFIformer/code/models/trainer.py\", line 10, in <module>\n",
            "\n",
            "  File \"/content/drive/My Drive/Duong/VFIformer/code/models/trainer.py\", line 10, in <module>\n",
            "    from .trainer import Trainer\n",
            "  File \"/content/drive/My Drive/Duong/VFIformer/code/models/trainer.py\", line 10, in <module>\n",
            "    from .trainer import Trainer\n",
            "  File \"/content/drive/My Drive/Duong/VFIformer/code/models/trainer.py\", line 10, in <module>\n",
            "    from tensorboardX import SummaryWriter    \n",
            "from tensorboardX import SummaryWriter    \n",
            "ModuleNotFoundError    from tensorboardX import SummaryWriter: ModuleNotFoundError\n",
            "from tensorboardX import SummaryWriterNo module named 'tensorboardX': \n",
            "\n",
            "ModuleNotFoundErrorNo module named 'tensorboardX': \n",
            "No module named 'tensorboardX'ModuleNotFoundError\n",
            ": No module named 'tensorboardX'\n",
            "WARNING:torch.distributed.elastic.agent.server.api:Received 2 death signal, shutting down workers\n",
            "WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 401 closing signal SIGINT\n",
            "WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 402 closing signal SIGINT\n",
            "WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 403 closing signal SIGINT\n",
            "WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 404 closing signal SIGINT\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n",
            "    \"__main__\", mod_spec)\n",
            "  File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/distributed/launch.py\", line 193, in <module>\n",
            "    main()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/distributed/launch.py\", line 189, in main\n",
            "    launch(args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/distributed/launch.py\", line 174, in launch\n",
            "    run(args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/distributed/run.py\", line 755, in run\n",
            "    )(*cmd_args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/distributed/launcher/api.py\", line 131, in __call__\n",
            "    return launch_agent(self._config, self._entrypoint, list(args))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/distributed/launcher/api.py\", line 236, in launch_agent\n",
            "    result = agent.run()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/distributed/elastic/metrics/api.py\", line 125, in wrapper\n",
            "    result = f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/distributed/elastic/agent/server/api.py\", line 709, in run\n",
            "    result = self._invoke_run(role)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/distributed/elastic/agent/server/api.py\", line 850, in _invoke_run\n",
            "    time.sleep(monitor_interval)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/distributed/elastic/multiprocessing/api.py\", line 60, in _terminate_process_handler\n",
            "    raise SignalException(f\"Process {os.getpid()} got signal: {sigval}\", sigval=sigval)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/distributed/elastic/multiprocessing/api.py\", line 45, in __init__\n",
            "    def __init__(self, msg: str, sigval: signal.Signals) -> None:\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/distributed/elastic/multiprocessing/api.py\", line 60, in _terminate_process_handler\n",
            "    raise SignalException(f\"Process {os.getpid()} got signal: {sigval}\", sigval=sigval)\n",
            "torch.distributed.elastic.multiprocessing.api.SignalException: Process 377 got signal: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m torch.distributed.launch --nproc_per_node=4 --master_port=4174 train.py \\\n",
        "  --gpu_ids -1 --loss_flow --use_tb_logger --batch_size 24 --net_name IFNet \\\n",
        "  --name train_IFNet --max_iter 300 --crop_size 192 --save_epoch_freq 5 \\\n",
        "  --data_root \"/content/drive/My Drive/Duong/datasets/vimeo-samples\""
      ],
      "metadata": {
        "id": "f50QnvxmBFxX",
        "outputId": "cef6ad4f-1f39-4211-cf6b-72d148bcb6ac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*****************************************\n",
            "Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
            "*****************************************\n",
            "Disabled distributed training.\n",
            "2022-11-20 09:51:18,866 [INFO ]  Logging file is ./weights/train_IFNet/20221120_095118.log\n",
            "2022-11-20 09:51:18,867 [INFO ]  random_seed:0\n",
            "2022-11-20 09:51:18,867 [INFO ]  name:train_IFNet\n",
            "2022-11-20 09:51:18,868 [INFO ]  phase:train\n",
            "2022-11-20 09:51:18,868 [INFO ]  gpu_ids:[]\n",
            "2022-11-20 09:51:18,868 [INFO ]  launcher:none\n",
            "2022-11-20 09:51:18,868 [INFO ]  local_rank:1\n",
            "2022-11-20 09:51:18,868 [INFO ]  net_name:IFNet\n",
            "2022-11-20 09:51:18,869 [INFO ]  window_size:8\n",
            "2022-11-20 09:51:18,869 [INFO ]  data_root:/content/drive/My Drive/Duong/datasets/vimeo-samples\n",
            "2022-11-20 09:51:18,869 [INFO ]  trainset:VimeoDataset\n",
            "2022-11-20 09:51:18,869 [INFO ]  testset:VimeoDataset\n",
            "2022-11-20 09:51:18,869 [INFO ]  save_test_root:generated\n",
            "2022-11-20 09:51:18,870 [INFO ]  crop_size:192\n",
            "2022-11-20 09:51:18,870 [INFO ]  batch_size:24\n",
            "2022-11-20 09:51:18,870 [INFO ]  num_workers:4\n",
            "2022-11-20 09:51:18,871 [INFO ]  multi_scale:False\n",
            "2022-11-20 09:51:18,871 [INFO ]  data_augmentation:False\n",
            "2022-11-20 09:51:18,871 [INFO ]  lr:0.0001\n",
            "2022-11-20 09:51:18,871 [INFO ]  lr_D:0.0001\n",
            "2022-11-20 09:51:18,871 [INFO ]  weight_decay:0.0001\n",
            "2022-11-20 09:51:18,872 [INFO ]  start_iter:0\n",
            "2022-11-20 09:51:18,872 [INFO ]  max_iter:300\n",
            "2022-11-20 09:51:18,872 [INFO ]  loss_l1:False\n",
            "2022-11-20 09:51:18,872 [INFO ]  loss_ter:False\n",
            "2022-11-20 09:51:18,873 [INFO ]  loss_flow:True\n",
            "2022-11-20 09:51:18,873 [INFO ]  loss_perceptual:False\n",
            "2022-11-20 09:51:18,873 [INFO ]  loss_adv:False\n",
            "2022-11-20 09:51:18,873 [INFO ]  gan_type:WGAN_GP\n",
            "2022-11-20 09:51:18,874 [INFO ]  lambda_l1:1\n",
            "2022-11-20 09:51:18,874 [INFO ]  lambda_ter:1\n",
            "2022-11-20 09:51:18,874 [INFO ]  lambda_flow:0.01\n",
            "2022-11-20 09:51:18,877 [INFO ]  lambda_perceptual:1\n",
            "2022-11-20 09:51:18,877 [INFO ]  lambda_adv:0.005\n",
            "2022-11-20 09:51:18,877 [INFO ]  resume:\n",
            "2022-11-20 09:51:18,877 [INFO ]  resume_optim:\n",
            "2022-11-20 09:51:18,878 [INFO ]  resume_scheduler:\n",
            "2022-11-20 09:51:18,878 [INFO ]  resume_flownet:\n",
            "2022-11-20 09:51:18,878 [INFO ]  log_freq:10\n",
            "2022-11-20 09:51:18,878 [INFO ]  vis_freq:50000\n",
            "2022-11-20 09:51:18,878 [INFO ]  save_epoch_freq:5\n",
            "2022-11-20 09:51:18,879 [INFO ]  test_freq:100\n",
            "2022-11-20 09:51:18,879 [INFO ]  save_folder:./weights/train_IFNet\n",
            "2022-11-20 09:51:18,879 [INFO ]  vis_step_freq:100\n",
            "2022-11-20 09:51:18,879 [INFO ]  use_tb_logger:True\n",
            "2022-11-20 09:51:18,880 [INFO ]  save_test_results:False\n",
            "2022-11-20 09:51:18,883 [INFO ]  ref_level:1\n",
            "2022-11-20 09:51:18,883 [INFO ]  dist:False\n",
            "2022-11-20 09:51:18,884 [INFO ]  rank:-1\n",
            "2022-11-20 09:51:18,884 [INFO ]  vis_save_dir:./weights/train_IFNet/vis\n",
            "2022-11-20 09:51:18,884 [INFO ]  snapshot_save_dir:./weights/train_IFNet/snapshot\n",
            "Disabled distributed training.\n",
            "2022-11-20 09:51:18,909 [INFO ]  Logging file is ./weights/train_IFNet/20221120_095118.log\n",
            "2022-11-20 09:51:18,910 [INFO ]  random_seed:0\n",
            "2022-11-20 09:51:18,910 [INFO ]  name:train_IFNet\n",
            "2022-11-20 09:51:18,910 [INFO ]  phase:train\n",
            "2022-11-20 09:51:18,910 [INFO ]  gpu_ids:[]\n",
            "2022-11-20 09:51:18,911 [INFO ]  launcher:none\n",
            "2022-11-20 09:51:18,911 [INFO ]  local_rank:2\n",
            "2022-11-20 09:51:18,911 [INFO ]  net_name:IFNet\n",
            "2022-11-20 09:51:18,911 [INFO ]  window_size:8\n",
            "2022-11-20 09:51:18,911 [INFO ]  data_root:/content/drive/My Drive/Duong/datasets/vimeo-samples\n",
            "2022-11-20 09:51:18,912 [INFO ]  trainset:VimeoDataset\n",
            "2022-11-20 09:51:18,912 [INFO ]  testset:VimeoDataset\n",
            "2022-11-20 09:51:18,912 [INFO ]  save_test_root:generated\n",
            "2022-11-20 09:51:18,912 [INFO ]  crop_size:192\n",
            "2022-11-20 09:51:18,912 [INFO ]  batch_size:24\n",
            "2022-11-20 09:51:18,912 [INFO ]  num_workers:4\n",
            "2022-11-20 09:51:18,913 [INFO ]  multi_scale:False\n",
            "2022-11-20 09:51:18,913 [INFO ]  data_augmentation:False\n",
            "2022-11-20 09:51:18,913 [INFO ]  lr:0.0001\n",
            "2022-11-20 09:51:18,913 [INFO ]  lr_D:0.0001\n",
            "2022-11-20 09:51:18,913 [INFO ]  weight_decay:0.0001\n",
            "2022-11-20 09:51:18,914 [INFO ]  start_iter:0\n",
            "2022-11-20 09:51:18,914 [INFO ]  max_iter:300\n",
            "2022-11-20 09:51:18,914 [INFO ]  loss_l1:False\n",
            "2022-11-20 09:51:18,914 [INFO ]  loss_ter:False\n",
            "2022-11-20 09:51:18,914 [INFO ]  loss_flow:True\n",
            "2022-11-20 09:51:18,915 [INFO ]  loss_perceptual:False\n",
            "2022-11-20 09:51:18,915 [INFO ]  loss_adv:False\n",
            "2022-11-20 09:51:18,915 [INFO ]  gan_type:WGAN_GP\n",
            "2022-11-20 09:51:18,915 [INFO ]  lambda_l1:1\n",
            "2022-11-20 09:51:18,915 [INFO ]  lambda_ter:1\n",
            "2022-11-20 09:51:18,916 [INFO ]  lambda_flow:0.01\n",
            "2022-11-20 09:51:18,916 [INFO ]  lambda_perceptual:1\n",
            "2022-11-20 09:51:18,916 [INFO ]  lambda_adv:0.005\n",
            "2022-11-20 09:51:18,916 [INFO ]  resume:\n",
            "2022-11-20 09:51:18,916 [INFO ]  resume_optim:\n",
            "2022-11-20 09:51:18,916 [INFO ]  resume_scheduler:\n",
            "2022-11-20 09:51:18,917 [INFO ]  resume_flownet:\n",
            "2022-11-20 09:51:18,917 [INFO ]  log_freq:10\n",
            "2022-11-20 09:51:18,917 [INFO ]  vis_freq:50000\n",
            "2022-11-20 09:51:18,917 [INFO ]  save_epoch_freq:5\n",
            "2022-11-20 09:51:18,917 [INFO ]  test_freq:100\n",
            "2022-11-20 09:51:18,917 [INFO ]  save_folder:./weights/train_IFNet\n",
            "2022-11-20 09:51:18,918 [INFO ]  vis_step_freq:100\n",
            "2022-11-20 09:51:18,918 [INFO ]  use_tb_logger:True\n",
            "2022-11-20 09:51:18,918 [INFO ]  save_test_results:False\n",
            "2022-11-20 09:51:18,923 [INFO ]  ref_level:1\n",
            "2022-11-20 09:51:18,923 [INFO ]  dist:False\n",
            "2022-11-20 09:51:18,923 [INFO ]  rank:-1\n",
            "2022-11-20 09:51:18,924 [INFO ]  vis_save_dir:./weights/train_IFNet/vis\n",
            "2022-11-20 09:51:18,924 [INFO ]  snapshot_save_dir:./weights/train_IFNet/snapshot\n",
            "Disabled distributed training.\n",
            "2022-11-20 09:51:18,944 [INFO ]  Logging file is ./weights/train_IFNet/20221120_095118.log\n",
            "2022-11-20 09:51:18,944 [INFO ]  random_seed:0\n",
            "2022-11-20 09:51:18,944 [INFO ]  name:train_IFNet\n",
            "2022-11-20 09:51:18,944 [INFO ]  phase:train\n",
            "2022-11-20 09:51:18,945 [INFO ]  gpu_ids:[]\n",
            "2022-11-20 09:51:18,945 [INFO ]  launcher:none\n",
            "2022-11-20 09:51:18,945 [INFO ]  local_rank:3\n",
            "2022-11-20 09:51:18,945 [INFO ]  net_name:IFNet\n",
            "2022-11-20 09:51:18,945 [INFO ]  window_size:8\n",
            "2022-11-20 09:51:18,946 [INFO ]  data_root:/content/drive/My Drive/Duong/datasets/vimeo-samples\n",
            "2022-11-20 09:51:18,946 [INFO ]  trainset:VimeoDataset\n",
            "2022-11-20 09:51:18,946 [INFO ]  testset:VimeoDataset\n",
            "2022-11-20 09:51:18,946 [INFO ]  save_test_root:generated\n",
            "2022-11-20 09:51:18,946 [INFO ]  crop_size:192\n",
            "2022-11-20 09:51:18,946 [INFO ]  batch_size:24\n",
            "2022-11-20 09:51:18,947 [INFO ]  num_workers:4\n",
            "2022-11-20 09:51:18,947 [INFO ]  multi_scale:False\n",
            "2022-11-20 09:51:18,947 [INFO ]  data_augmentation:False\n",
            "2022-11-20 09:51:18,947 [INFO ]  lr:0.0001\n",
            "2022-11-20 09:51:18,947 [INFO ]  lr_D:0.0001\n",
            "2022-11-20 09:51:18,947 [INFO ]  weight_decay:0.0001\n",
            "2022-11-20 09:51:18,948 [INFO ]  start_iter:0\n",
            "2022-11-20 09:51:18,948 [INFO ]  max_iter:300\n",
            "2022-11-20 09:51:18,948 [INFO ]  loss_l1:False\n",
            "2022-11-20 09:51:18,948 [INFO ]  loss_ter:False\n",
            "2022-11-20 09:51:18,948 [INFO ]  loss_flow:True\n",
            "2022-11-20 09:51:18,948 [INFO ]  loss_perceptual:False\n",
            "2022-11-20 09:51:18,948 [INFO ]  loss_adv:False\n",
            "2022-11-20 09:51:18,949 [INFO ]  gan_type:WGAN_GP\n",
            "2022-11-20 09:51:18,949 [INFO ]  lambda_l1:1\n",
            "2022-11-20 09:51:18,949 [INFO ]  lambda_ter:1\n",
            "2022-11-20 09:51:18,949 [INFO ]  lambda_flow:0.01\n",
            "2022-11-20 09:51:18,949 [INFO ]  lambda_perceptual:1\n",
            "2022-11-20 09:51:18,949 [INFO ]  lambda_adv:0.005\n",
            "2022-11-20 09:51:18,950 [INFO ]  resume:\n",
            "2022-11-20 09:51:18,950 [INFO ]  resume_optim:\n",
            "2022-11-20 09:51:18,950 [INFO ]  resume_scheduler:\n",
            "2022-11-20 09:51:18,950 [INFO ]  resume_flownet:\n",
            "2022-11-20 09:51:18,950 [INFO ]  log_freq:10\n",
            "2022-11-20 09:51:18,950 [INFO ]  vis_freq:50000\n",
            "2022-11-20 09:51:18,950 [INFO ]  save_epoch_freq:5\n",
            "2022-11-20 09:51:18,951 [INFO ]  test_freq:100\n",
            "2022-11-20 09:51:18,951 [INFO ]  save_folder:./weights/train_IFNet\n",
            "2022-11-20 09:51:18,951 [INFO ]  vis_step_freq:100\n",
            "2022-11-20 09:51:18,951 [INFO ]  use_tb_logger:True\n",
            "2022-11-20 09:51:18,951 [INFO ]  save_test_results:False\n",
            "2022-11-20 09:51:18,951 [INFO ]  ref_level:1\n",
            "2022-11-20 09:51:18,952 [INFO ]  dist:False\n",
            "2022-11-20 09:51:18,952 [INFO ]  rank:-1\n",
            "2022-11-20 09:51:18,952 [INFO ]  vis_save_dir:./weights/train_IFNet/vis\n",
            "2022-11-20 09:51:18,952 [INFO ]  snapshot_save_dir:./weights/train_IFNet/snapshot\n",
            "Disabled distributed training.\n",
            "2022-11-20 09:51:18,983 [INFO ]  Logging file is ./weights/train_IFNet/20221120_095118.log\n",
            "2022-11-20 09:51:18,984 [INFO ]  random_seed:0\n",
            "2022-11-20 09:51:18,984 [INFO ]  name:train_IFNet\n",
            "2022-11-20 09:51:18,984 [INFO ]  phase:train\n",
            "2022-11-20 09:51:18,984 [INFO ]  gpu_ids:[]\n",
            "2022-11-20 09:51:18,984 [INFO ]  launcher:none\n",
            "2022-11-20 09:51:18,985 [INFO ]  local_rank:0\n",
            "2022-11-20 09:51:18,985 [INFO ]  net_name:IFNet\n",
            "2022-11-20 09:51:18,985 [INFO ]  window_size:8\n",
            "2022-11-20 09:51:18,985 [INFO ]  data_root:/content/drive/My Drive/Duong/datasets/vimeo-samples\n",
            "2022-11-20 09:51:18,986 [INFO ]  trainset:VimeoDataset\n",
            "2022-11-20 09:51:18,986 [INFO ]  testset:VimeoDataset\n",
            "2022-11-20 09:51:18,986 [INFO ]  save_test_root:generated\n",
            "2022-11-20 09:51:18,986 [INFO ]  crop_size:192\n",
            "2022-11-20 09:51:18,986 [INFO ]  batch_size:24\n",
            "2022-11-20 09:51:18,987 [INFO ]  num_workers:4\n",
            "2022-11-20 09:51:18,987 [INFO ]  multi_scale:False\n",
            "2022-11-20 09:51:18,987 [INFO ]  data_augmentation:False\n",
            "2022-11-20 09:51:18,987 [INFO ]  lr:0.0001\n",
            "2022-11-20 09:51:18,987 [INFO ]  lr_D:0.0001\n",
            "2022-11-20 09:51:18,988 [INFO ]  weight_decay:0.0001\n",
            "2022-11-20 09:51:18,988 [INFO ]  start_iter:0\n",
            "2022-11-20 09:51:18,988 [INFO ]  max_iter:300\n",
            "2022-11-20 09:51:18,988 [INFO ]  loss_l1:False\n",
            "2022-11-20 09:51:18,988 [INFO ]  loss_ter:False\n",
            "2022-11-20 09:51:18,989 [INFO ]  loss_flow:True\n",
            "2022-11-20 09:51:18,989 [INFO ]  loss_perceptual:False\n",
            "2022-11-20 09:51:18,989 [INFO ]  loss_adv:False\n",
            "2022-11-20 09:51:18,989 [INFO ]  gan_type:WGAN_GP\n",
            "2022-11-20 09:51:18,989 [INFO ]  lambda_l1:1\n",
            "2022-11-20 09:51:18,990 [INFO ]  lambda_ter:1\n",
            "2022-11-20 09:51:18,990 [INFO ]  lambda_flow:0.01\n",
            "2022-11-20 09:51:18,990 [INFO ]  lambda_perceptual:1\n",
            "2022-11-20 09:51:18,990 [INFO ]  lambda_adv:0.005\n",
            "2022-11-20 09:51:18,990 [INFO ]  resume:\n",
            "2022-11-20 09:51:18,991 [INFO ]  resume_optim:\n",
            "2022-11-20 09:51:18,991 [INFO ]  resume_scheduler:\n",
            "2022-11-20 09:51:18,991 [INFO ]  resume_flownet:\n",
            "2022-11-20 09:51:18,991 [INFO ]  log_freq:10\n",
            "2022-11-20 09:51:18,991 [INFO ]  vis_freq:50000\n",
            "2022-11-20 09:51:18,992 [INFO ]  save_epoch_freq:5\n",
            "2022-11-20 09:51:18,992 [INFO ]  test_freq:100\n",
            "2022-11-20 09:51:18,992 [INFO ]  save_folder:./weights/train_IFNet\n",
            "2022-11-20 09:51:18,992 [INFO ]  vis_step_freq:100\n",
            "2022-11-20 09:51:18,992 [INFO ]  use_tb_logger:True\n",
            "2022-11-20 09:51:18,992 [INFO ]  save_test_results:False\n",
            "2022-11-20 09:51:18,993 [INFO ]  ref_level:1\n",
            "2022-11-20 09:51:18,993 [INFO ]  dist:False\n",
            "2022-11-20 09:51:18,993 [INFO ]  rank:-1\n",
            "2022-11-20 09:51:18,993 [INFO ]  vis_save_dir:./weights/train_IFNet/vis\n",
            "2022-11-20 09:51:18,993 [INFO ]  snapshot_save_dir:./weights/train_IFNet/snapshot\n",
            "Killing subprocess 714\n",
            "Killing subprocess 715\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n",
            "    \"__main__\", mod_spec)\n",
            "  File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/distributed/launch.py\", line 340, in <module>\n",
            "    main()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/distributed/launch.py\", line 332, in main\n",
            "    time.sleep(1)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/distributed/launch.py\", line 295, in sigkill_handler\n",
            "    print(f\"Killing subprocess {process.pid}\")\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/distributed/launch.py\", line 295, in sigkill_handler\n",
            "    print(f\"Killing subprocess {process.pid}\")\n",
            "RuntimeError: reentrant call inside <_io.BufferedWriter name='<stdout>'>\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "  File \"train.py\", line 152, in <module>\n",
            "Traceback (most recent call last):\n",
            "  File \"train.py\", line 152, in <module>\n",
            "  File \"train.py\", line 152, in <module>\n",
            "    main()\n",
            "  File \"train.py\", line 148, in main\n",
            "    main()\n",
            "  File \"train.py\", line 148, in main\n",
            "    main()\n",
            "  File \"train.py\", line 148, in main\n",
            "    trainer = Trainer(args)\n",
            "  File \"/content/drive/MyDrive/Duong/VFIformer/code/models/trainer.py\", line 43, in __init__\n",
            "    trainer = Trainer(args)\n",
            "  File \"/content/drive/MyDrive/Duong/VFIformer/code/models/trainer.py\", line 43, in __init__\n",
            "    trainer = Trainer(args)\n",
            "  File \"/content/drive/MyDrive/Duong/VFIformer/code/models/trainer.py\", line 43, in __init__\n",
            "    self.train_dataset = trainset_(self.args)\n",
            "  File \"/content/drive/MyDrive/Duong/VFIformer/code/dataloader/dataset.py\", line 22, in __init__\n",
            "    self.train_dataset = trainset_(self.args)\n",
            "  File \"/content/drive/MyDrive/Duong/VFIformer/code/dataloader/dataset.py\", line 22, in __init__\n",
            "    self.train_dataset = trainset_(self.args)\n",
            "  File \"/content/drive/MyDrive/Duong/VFIformer/code/dataloader/dataset.py\", line 22, in __init__\n",
            "    self.load_data()\n",
            "  File \"/content/drive/MyDrive/Duong/VFIformer/code/dataloader/dataset.py\", line 40, in load_data\n",
            "        self.load_data()\n",
            "self.load_data()  File \"/content/drive/MyDrive/Duong/VFIformer/code/dataloader/dataset.py\", line 40, in load_data\n",
            "\n",
            "  File \"/content/drive/MyDrive/Duong/VFIformer/code/dataloader/dataset.py\", line 40, in load_data\n",
            "    pair = sorted(glob.glob(os.path.join(self.data_root, 'sequences', name, '*.png')))    \n",
            "  File \"/usr/lib/python3.7/glob.py\", line 20, in glob\n",
            "pair = sorted(glob.glob(os.path.join(self.data_root, 'sequences', name, '*.png')))\n",
            "  File \"/usr/lib/python3.7/glob.py\", line 20, in glob\n",
            "    pair = sorted(glob.glob(os.path.join(self.data_root, 'sequences', name, '*.png')))\n",
            "  File \"/usr/lib/python3.7/glob.py\", line 20, in glob\n",
            "        return list(iglob(pathname, recursive=recursive))return list(iglob(pathname, recursive=recursive))\n",
            "\n",
            "  File \"/usr/lib/python3.7/glob.py\", line 72, in _iglob\n",
            "  File \"/usr/lib/python3.7/glob.py\", line 72, in _iglob\n",
            "            return list(iglob(pathname, recursive=recursive))\n",
            "  File \"/usr/lib/python3.7/glob.py\", line 72, in _iglob\n",
            "    for name in glob_in_dir(dirname, basename, dironly):\n",
            "  File \"/usr/lib/python3.7/glob.py\", line 80, in _glob1\n",
            "    for name in glob_in_dir(dirname, basename, dironly):\n",
            "  File \"/usr/lib/python3.7/glob.py\", line 80, in _glob1\n",
            "    for name in glob_in_dir(dirname, basename, dironly):\n",
            "  File \"/usr/lib/python3.7/glob.py\", line 80, in _glob1\n",
            "    names = list(_iterdir(dirname, dironly))\n",
            "  File \"/usr/lib/python3.7/glob.py\", line 121, in _iterdir\n",
            "    names = list(_iterdir(dirname, dironly))names = list(_iterdir(dirname, dironly))\n",
            "  File \"/usr/lib/python3.7/glob.py\", line 121, in _iterdir\n",
            "\n",
            "with os.scandir(dirname) as it:  File \"/usr/lib/python3.7/glob.py\", line 121, in _iterdir\n",
            "\n",
            "    KeyboardInterrupt    \n",
            "with os.scandir(dirname) as it:with os.scandir(dirname) as it:\n",
            "KeyboardInterrupt\n",
            "KeyboardInterrupt\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m torch.distributed.launch --nproc_per_node=1 --master_port=4175 train.py --launcher pytorch --gpu_ids 0 \\\n",
        "            --loss_l1 --loss_ter --loss_flow --use_tb_logger --batch_size 24 --net_name VFIformer --name train_VFIformerFull --max_iter 300 \\\n",
        "            --crop_size 192 --save_epoch_freq 5 --data_root \"/content/drive/My Drive/Duong/datasets/smallest-2\" \\\n",
        "            --num_workers 2"
      ],
      "metadata": {
        "id": "zEzvnwE0HbE5",
        "outputId": "7d25db2b-e3bc-4889-c006-facbb5f4729b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:root:Logging file is ./weights/train_VFIformerFull/20221120_121116.log\n",
            "2022-11-20 12:11:16,241 [INFO ]  Logging file is ./weights/train_VFIformerFull/20221120_121116.log\n",
            "INFO:root:random_seed:0\n",
            "2022-11-20 12:11:16,241 [INFO ]  random_seed:0\n",
            "INFO:root:name:train_VFIformerFull\n",
            "2022-11-20 12:11:16,242 [INFO ]  name:train_VFIformerFull\n",
            "INFO:root:phase:train\n",
            "2022-11-20 12:11:16,242 [INFO ]  phase:train\n",
            "INFO:root:gpu_ids:[0]\n",
            "2022-11-20 12:11:16,242 [INFO ]  gpu_ids:[0]\n",
            "INFO:root:launcher:pytorch\n",
            "2022-11-20 12:11:16,242 [INFO ]  launcher:pytorch\n",
            "INFO:root:local_rank:0\n",
            "2022-11-20 12:11:16,242 [INFO ]  local_rank:0\n",
            "INFO:root:net_name:VFIformer\n",
            "2022-11-20 12:11:16,242 [INFO ]  net_name:VFIformer\n",
            "INFO:root:window_size:8\n",
            "2022-11-20 12:11:16,242 [INFO ]  window_size:8\n",
            "INFO:root:data_root:/content/drive/My Drive/Duong/datasets/smallest-2\n",
            "2022-11-20 12:11:16,242 [INFO ]  data_root:/content/drive/My Drive/Duong/datasets/smallest-2\n",
            "INFO:root:trainset:VimeoDataset\n",
            "2022-11-20 12:11:16,242 [INFO ]  trainset:VimeoDataset\n",
            "INFO:root:testset:VimeoDataset\n",
            "2022-11-20 12:11:16,242 [INFO ]  testset:VimeoDataset\n",
            "INFO:root:save_test_root:generated\n",
            "2022-11-20 12:11:16,243 [INFO ]  save_test_root:generated\n",
            "INFO:root:crop_size:192\n",
            "2022-11-20 12:11:16,243 [INFO ]  crop_size:192\n",
            "INFO:root:batch_size:24\n",
            "2022-11-20 12:11:16,243 [INFO ]  batch_size:24\n",
            "INFO:root:num_workers:2\n",
            "2022-11-20 12:11:16,243 [INFO ]  num_workers:2\n",
            "INFO:root:multi_scale:False\n",
            "2022-11-20 12:11:16,243 [INFO ]  multi_scale:False\n",
            "INFO:root:data_augmentation:False\n",
            "2022-11-20 12:11:16,243 [INFO ]  data_augmentation:False\n",
            "INFO:root:lr:0.0001\n",
            "2022-11-20 12:11:16,243 [INFO ]  lr:0.0001\n",
            "INFO:root:lr_D:0.0001\n",
            "2022-11-20 12:11:16,243 [INFO ]  lr_D:0.0001\n",
            "INFO:root:weight_decay:0.0001\n",
            "2022-11-20 12:11:16,243 [INFO ]  weight_decay:0.0001\n",
            "INFO:root:start_iter:0\n",
            "2022-11-20 12:11:16,243 [INFO ]  start_iter:0\n",
            "INFO:root:max_iter:300\n",
            "2022-11-20 12:11:16,244 [INFO ]  max_iter:300\n",
            "INFO:root:loss_l1:True\n",
            "2022-11-20 12:11:16,244 [INFO ]  loss_l1:True\n",
            "INFO:root:loss_ter:True\n",
            "2022-11-20 12:11:16,244 [INFO ]  loss_ter:True\n",
            "INFO:root:loss_flow:True\n",
            "2022-11-20 12:11:16,244 [INFO ]  loss_flow:True\n",
            "INFO:root:loss_perceptual:False\n",
            "2022-11-20 12:11:16,244 [INFO ]  loss_perceptual:False\n",
            "INFO:root:loss_adv:False\n",
            "2022-11-20 12:11:16,244 [INFO ]  loss_adv:False\n",
            "INFO:root:gan_type:WGAN_GP\n",
            "2022-11-20 12:11:16,244 [INFO ]  gan_type:WGAN_GP\n",
            "INFO:root:lambda_l1:1\n",
            "2022-11-20 12:11:16,244 [INFO ]  lambda_l1:1\n",
            "INFO:root:lambda_ter:1\n",
            "2022-11-20 12:11:16,244 [INFO ]  lambda_ter:1\n",
            "INFO:root:lambda_flow:0.01\n",
            "2022-11-20 12:11:16,244 [INFO ]  lambda_flow:0.01\n",
            "INFO:root:lambda_perceptual:1\n",
            "2022-11-20 12:11:16,245 [INFO ]  lambda_perceptual:1\n",
            "INFO:root:lambda_adv:0.005\n",
            "2022-11-20 12:11:16,245 [INFO ]  lambda_adv:0.005\n",
            "INFO:root:resume:\n",
            "2022-11-20 12:11:16,245 [INFO ]  resume:\n",
            "INFO:root:resume_optim:\n",
            "2022-11-20 12:11:16,245 [INFO ]  resume_optim:\n",
            "INFO:root:resume_scheduler:\n",
            "2022-11-20 12:11:16,245 [INFO ]  resume_scheduler:\n",
            "INFO:root:resume_flownet:\n",
            "2022-11-20 12:11:16,245 [INFO ]  resume_flownet:\n",
            "INFO:root:log_freq:10\n",
            "2022-11-20 12:11:16,245 [INFO ]  log_freq:10\n",
            "INFO:root:vis_freq:50000\n",
            "2022-11-20 12:11:16,245 [INFO ]  vis_freq:50000\n",
            "INFO:root:save_epoch_freq:5\n",
            "2022-11-20 12:11:16,245 [INFO ]  save_epoch_freq:5\n",
            "INFO:root:test_freq:100\n",
            "2022-11-20 12:11:16,245 [INFO ]  test_freq:100\n",
            "INFO:root:save_folder:./weights/train_VFIformerFull\n",
            "2022-11-20 12:11:16,245 [INFO ]  save_folder:./weights/train_VFIformerFull\n",
            "INFO:root:vis_step_freq:100\n",
            "2022-11-20 12:11:16,246 [INFO ]  vis_step_freq:100\n",
            "INFO:root:use_tb_logger:True\n",
            "2022-11-20 12:11:16,246 [INFO ]  use_tb_logger:True\n",
            "INFO:root:save_test_results:False\n",
            "2022-11-20 12:11:16,246 [INFO ]  save_test_results:False\n",
            "INFO:root:ref_level:1\n",
            "2022-11-20 12:11:16,246 [INFO ]  ref_level:1\n",
            "INFO:root:dist:True\n",
            "2022-11-20 12:11:16,246 [INFO ]  dist:True\n",
            "INFO:root:world_size:1\n",
            "2022-11-20 12:11:16,246 [INFO ]  world_size:1\n",
            "INFO:root:rank:0\n",
            "2022-11-20 12:11:16,246 [INFO ]  rank:0\n",
            "INFO:root:vis_save_dir:./weights/train_VFIformerFull/vis\n",
            "2022-11-20 12:11:16,246 [INFO ]  vis_save_dir:./weights/train_VFIformerFull/vis\n",
            "INFO:root:snapshot_save_dir:./weights/train_VFIformerFull/snapshot\n",
            "2022-11-20 12:11:16,246 [INFO ]  snapshot_save_dir:./weights/train_VFIformerFull/snapshot\n",
            "INFO:root:----- generator parameters: 24.166930 -----\n",
            "2022-11-20 12:11:20,475 [INFO ]  ----- generator parameters: 24.166930 -----\n",
            "INFO:root:init criterion and optimizer...\n",
            "2022-11-20 12:11:20,476 [INFO ]  init criterion and optimizer...\n",
            "INFO:root:  using l1 loss...\n",
            "2022-11-20 12:11:20,478 [INFO ]    using l1 loss...\n",
            "INFO:root:  using flow loss...\n",
            "2022-11-20 12:11:20,478 [INFO ]    using flow loss...\n",
            "INFO:root:  using ter loss...\n",
            "2022-11-20 12:11:20,478 [INFO ]    using ter loss...\n",
            "INFO:root:training on  ...VimeoDataset\n",
            "2022-11-20 12:11:20,479 [INFO ]  training on  ...VimeoDataset\n",
            "INFO:root:1 training samples\n",
            "2022-11-20 12:11:20,479 [INFO ]  1 training samples\n",
            "INFO:root:the init lr: 0.000100\n",
            "2022-11-20 12:11:20,479 [INFO ]  the init lr: 0.000100\n",
            "INFO:root:Saving state, epoch: 0 iter:0\n",
            "2022-11-20 12:11:22,281 [INFO ]  Saving state, epoch: 0 iter:0\n",
            "INFO:root:Saving state, epoch: 5 iter:0\n",
            "2022-11-20 12:11:30,953 [INFO ]  Saving state, epoch: 5 iter:0\n",
            "INFO:root:Saving state, epoch: 10 iter:0\n",
            "2022-11-20 12:11:39,805 [INFO ]  Saving state, epoch: 10 iter:0\n",
            "INFO:root:Saving state, epoch: 15 iter:0\n",
            "2022-11-20 12:11:48,806 [INFO ]  Saving state, epoch: 15 iter:0\n",
            "INFO:root:Saving state, epoch: 20 iter:0\n",
            "2022-11-20 12:11:57,609 [INFO ]  Saving state, epoch: 20 iter:0\n",
            "INFO:root:Saving state, epoch: 25 iter:0\n",
            "2022-11-20 12:12:06,455 [INFO ]  Saving state, epoch: 25 iter:0\n",
            "INFO:root:Saving state, epoch: 30 iter:0\n",
            "2022-11-20 12:12:15,300 [INFO ]  Saving state, epoch: 30 iter:0\n",
            "INFO:root:Saving state, epoch: 35 iter:0\n",
            "2022-11-20 12:12:24,306 [INFO ]  Saving state, epoch: 35 iter:0\n",
            "INFO:root:Saving state, epoch: 40 iter:0\n",
            "2022-11-20 12:12:33,139 [INFO ]  Saving state, epoch: 40 iter:0\n",
            "INFO:root:Saving state, epoch: 45 iter:0\n",
            "2022-11-20 12:12:41,868 [INFO ]  Saving state, epoch: 45 iter:0\n",
            "INFO:root:Saving state, epoch: 50 iter:0\n",
            "2022-11-20 12:12:50,610 [INFO ]  Saving state, epoch: 50 iter:0\n",
            "INFO:root:Saving state, epoch: 55 iter:0\n",
            "2022-11-20 12:12:59,505 [INFO ]  Saving state, epoch: 55 iter:0\n",
            "INFO:root:Saving state, epoch: 60 iter:0\n",
            "2022-11-20 12:13:08,373 [INFO ]  Saving state, epoch: 60 iter:0\n",
            "INFO:root:Saving state, epoch: 65 iter:0\n",
            "2022-11-20 12:13:17,207 [INFO ]  Saving state, epoch: 65 iter:0\n",
            "INFO:root:Saving state, epoch: 70 iter:0\n",
            "2022-11-20 12:13:25,944 [INFO ]  Saving state, epoch: 70 iter:0\n",
            "INFO:root:Saving state, epoch: 75 iter:0\n",
            "2022-11-20 12:13:34,828 [INFO ]  Saving state, epoch: 75 iter:0\n",
            "INFO:root:Saving state, epoch: 80 iter:0\n",
            "2022-11-20 12:13:43,703 [INFO ]  Saving state, epoch: 80 iter:0\n",
            "INFO:root:Saving state, epoch: 85 iter:0\n",
            "2022-11-20 12:13:52,505 [INFO ]  Saving state, epoch: 85 iter:0\n",
            "INFO:root:Saving state, epoch: 90 iter:0\n",
            "2022-11-20 12:14:01,297 [INFO ]  Saving state, epoch: 90 iter:0\n",
            "INFO:root:Saving state, epoch: 95 iter:0\n",
            "2022-11-20 12:14:10,572 [INFO ]  Saving state, epoch: 95 iter:0\n",
            "INFO:root:Saving state, epoch: 100 iter:0\n",
            "2022-11-20 12:14:19,249 [INFO ]  Saving state, epoch: 100 iter:0\n",
            "INFO:root:Saving state, epoch: 105 iter:0\n",
            "2022-11-20 12:14:28,028 [INFO ]  Saving state, epoch: 105 iter:0\n",
            "INFO:root:Saving state, epoch: 110 iter:0\n",
            "2022-11-20 12:14:36,702 [INFO ]  Saving state, epoch: 110 iter:0\n",
            "INFO:root:Saving state, epoch: 115 iter:0\n",
            "2022-11-20 12:14:45,511 [INFO ]  Saving state, epoch: 115 iter:0\n",
            "INFO:root:Saving state, epoch: 120 iter:0\n",
            "2022-11-20 12:14:54,356 [INFO ]  Saving state, epoch: 120 iter:0\n",
            "INFO:root:Saving state, epoch: 125 iter:0\n",
            "2022-11-20 12:15:03,529 [INFO ]  Saving state, epoch: 125 iter:0\n",
            "INFO:root:Saving state, epoch: 130 iter:0\n",
            "2022-11-20 12:15:12,412 [INFO ]  Saving state, epoch: 130 iter:0\n",
            "INFO:root:Saving state, epoch: 135 iter:0\n",
            "2022-11-20 12:15:21,218 [INFO ]  Saving state, epoch: 135 iter:0\n",
            "INFO:root:Saving state, epoch: 140 iter:0\n",
            "2022-11-20 12:15:30,013 [INFO ]  Saving state, epoch: 140 iter:0\n",
            "INFO:root:Saving state, epoch: 145 iter:0\n",
            "2022-11-20 12:15:38,888 [INFO ]  Saving state, epoch: 145 iter:0\n",
            "INFO:root:Saving state, epoch: 150 iter:0\n",
            "2022-11-20 12:15:47,677 [INFO ]  Saving state, epoch: 150 iter:0\n",
            "INFO:root:Saving state, epoch: 155 iter:0\n",
            "2022-11-20 12:15:56,351 [INFO ]  Saving state, epoch: 155 iter:0\n",
            "INFO:root:Saving state, epoch: 160 iter:0\n",
            "2022-11-20 12:16:05,465 [INFO ]  Saving state, epoch: 160 iter:0\n",
            "INFO:root:Saving state, epoch: 165 iter:0\n",
            "2022-11-20 12:16:15,226 [INFO ]  Saving state, epoch: 165 iter:0\n",
            "INFO:root:Saving state, epoch: 170 iter:0\n",
            "2022-11-20 12:16:24,783 [INFO ]  Saving state, epoch: 170 iter:0\n",
            "INFO:root:Saving state, epoch: 175 iter:0\n",
            "2022-11-20 12:16:33,534 [INFO ]  Saving state, epoch: 175 iter:0\n",
            "INFO:root:Saving state, epoch: 180 iter:0\n",
            "2022-11-20 12:16:42,225 [INFO ]  Saving state, epoch: 180 iter:0\n",
            "INFO:root:Saving state, epoch: 185 iter:0\n",
            "2022-11-20 12:16:50,932 [INFO ]  Saving state, epoch: 185 iter:0\n",
            "Killing subprocess 7273\n",
            "Main process received SIGINT, exiting\n",
            "/usr/lib/python3.7/multiprocessing/semaphore_tracker.py:144: UserWarning: semaphore_tracker: There appear to be 17 leaked semaphores to clean up at shutdown\n",
            "  len(cache))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m torch.distributed.launch --nproc_per_node=1 --master_port=4175 train.py --launcher pytorch --gpu_ids 0 \\\n",
        "            --loss_l1 --loss_ter --loss_flow --use_tb_logger --batch_size 24 --net_name VFIformerSmall --name train_VFIformerSmall --max_iter 300 \\\n",
        "            --crop_size 192 --save_epoch_freq 5 --data_root \"/content/drive/My Drive/Duong/datasets/smallest\" \\\n",
        "            --num_workers 2"
      ],
      "metadata": {
        "id": "j4UXMw7nzJ-s",
        "outputId": "664fdbe0-0ff5-45cf-d755-2386d245c1ba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:root:Logging file is ./weights/train_VFIformerSmall/20221120_115145.log\n",
            "2022-11-20 11:51:45,654 [INFO ]  Logging file is ./weights/train_VFIformerSmall/20221120_115145.log\n",
            "INFO:root:random_seed:0\n",
            "2022-11-20 11:51:45,654 [INFO ]  random_seed:0\n",
            "INFO:root:name:train_VFIformerSmall\n",
            "2022-11-20 11:51:45,654 [INFO ]  name:train_VFIformerSmall\n",
            "INFO:root:phase:train\n",
            "2022-11-20 11:51:45,655 [INFO ]  phase:train\n",
            "INFO:root:gpu_ids:[0]\n",
            "2022-11-20 11:51:45,655 [INFO ]  gpu_ids:[0]\n",
            "INFO:root:launcher:pytorch\n",
            "2022-11-20 11:51:45,655 [INFO ]  launcher:pytorch\n",
            "INFO:root:local_rank:0\n",
            "2022-11-20 11:51:45,655 [INFO ]  local_rank:0\n",
            "INFO:root:net_name:VFIformerSmall\n",
            "2022-11-20 11:51:45,655 [INFO ]  net_name:VFIformerSmall\n",
            "INFO:root:window_size:8\n",
            "2022-11-20 11:51:45,655 [INFO ]  window_size:8\n",
            "INFO:root:data_root:/content/drive/My Drive/Duong/datasets/smallest\n",
            "2022-11-20 11:51:45,655 [INFO ]  data_root:/content/drive/My Drive/Duong/datasets/smallest\n",
            "INFO:root:trainset:VimeoDataset\n",
            "2022-11-20 11:51:45,655 [INFO ]  trainset:VimeoDataset\n",
            "INFO:root:testset:VimeoDataset\n",
            "2022-11-20 11:51:45,655 [INFO ]  testset:VimeoDataset\n",
            "INFO:root:save_test_root:generated\n",
            "2022-11-20 11:51:45,655 [INFO ]  save_test_root:generated\n",
            "INFO:root:crop_size:192\n",
            "2022-11-20 11:51:45,656 [INFO ]  crop_size:192\n",
            "INFO:root:batch_size:24\n",
            "2022-11-20 11:51:45,656 [INFO ]  batch_size:24\n",
            "INFO:root:num_workers:2\n",
            "2022-11-20 11:51:45,656 [INFO ]  num_workers:2\n",
            "INFO:root:multi_scale:False\n",
            "2022-11-20 11:51:45,656 [INFO ]  multi_scale:False\n",
            "INFO:root:data_augmentation:False\n",
            "2022-11-20 11:51:45,656 [INFO ]  data_augmentation:False\n",
            "INFO:root:lr:0.0001\n",
            "2022-11-20 11:51:45,656 [INFO ]  lr:0.0001\n",
            "INFO:root:lr_D:0.0001\n",
            "2022-11-20 11:51:45,656 [INFO ]  lr_D:0.0001\n",
            "INFO:root:weight_decay:0.0001\n",
            "2022-11-20 11:51:45,656 [INFO ]  weight_decay:0.0001\n",
            "INFO:root:start_iter:0\n",
            "2022-11-20 11:51:45,656 [INFO ]  start_iter:0\n",
            "INFO:root:max_iter:300\n",
            "2022-11-20 11:51:45,656 [INFO ]  max_iter:300\n",
            "INFO:root:loss_l1:True\n",
            "2022-11-20 11:51:45,657 [INFO ]  loss_l1:True\n",
            "INFO:root:loss_ter:True\n",
            "2022-11-20 11:51:45,657 [INFO ]  loss_ter:True\n",
            "INFO:root:loss_flow:True\n",
            "2022-11-20 11:51:45,657 [INFO ]  loss_flow:True\n",
            "INFO:root:loss_perceptual:False\n",
            "2022-11-20 11:51:45,657 [INFO ]  loss_perceptual:False\n",
            "INFO:root:loss_adv:False\n",
            "2022-11-20 11:51:45,657 [INFO ]  loss_adv:False\n",
            "INFO:root:gan_type:WGAN_GP\n",
            "2022-11-20 11:51:45,657 [INFO ]  gan_type:WGAN_GP\n",
            "INFO:root:lambda_l1:1\n",
            "2022-11-20 11:51:45,657 [INFO ]  lambda_l1:1\n",
            "INFO:root:lambda_ter:1\n",
            "2022-11-20 11:51:45,657 [INFO ]  lambda_ter:1\n",
            "INFO:root:lambda_flow:0.01\n",
            "2022-11-20 11:51:45,657 [INFO ]  lambda_flow:0.01\n",
            "INFO:root:lambda_perceptual:1\n",
            "2022-11-20 11:51:45,657 [INFO ]  lambda_perceptual:1\n",
            "INFO:root:lambda_adv:0.005\n",
            "2022-11-20 11:51:45,658 [INFO ]  lambda_adv:0.005\n",
            "INFO:root:resume:\n",
            "2022-11-20 11:51:45,658 [INFO ]  resume:\n",
            "INFO:root:resume_optim:\n",
            "2022-11-20 11:51:45,658 [INFO ]  resume_optim:\n",
            "INFO:root:resume_scheduler:\n",
            "2022-11-20 11:51:45,658 [INFO ]  resume_scheduler:\n",
            "INFO:root:resume_flownet:\n",
            "2022-11-20 11:51:45,658 [INFO ]  resume_flownet:\n",
            "INFO:root:log_freq:10\n",
            "2022-11-20 11:51:45,658 [INFO ]  log_freq:10\n",
            "INFO:root:vis_freq:50000\n",
            "2022-11-20 11:51:45,658 [INFO ]  vis_freq:50000\n",
            "INFO:root:save_epoch_freq:5\n",
            "2022-11-20 11:51:45,658 [INFO ]  save_epoch_freq:5\n",
            "INFO:root:test_freq:100\n",
            "2022-11-20 11:51:45,658 [INFO ]  test_freq:100\n",
            "INFO:root:save_folder:./weights/train_VFIformerSmall\n",
            "2022-11-20 11:51:45,658 [INFO ]  save_folder:./weights/train_VFIformerSmall\n",
            "INFO:root:vis_step_freq:100\n",
            "2022-11-20 11:51:45,659 [INFO ]  vis_step_freq:100\n",
            "INFO:root:use_tb_logger:True\n",
            "2022-11-20 11:51:45,659 [INFO ]  use_tb_logger:True\n",
            "INFO:root:save_test_results:False\n",
            "2022-11-20 11:51:45,659 [INFO ]  save_test_results:False\n",
            "INFO:root:ref_level:1\n",
            "2022-11-20 11:51:45,659 [INFO ]  ref_level:1\n",
            "INFO:root:dist:True\n",
            "2022-11-20 11:51:45,659 [INFO ]  dist:True\n",
            "INFO:root:world_size:1\n",
            "2022-11-20 11:51:45,659 [INFO ]  world_size:1\n",
            "INFO:root:rank:0\n",
            "2022-11-20 11:51:45,659 [INFO ]  rank:0\n",
            "INFO:root:vis_save_dir:./weights/train_VFIformerSmall/vis\n",
            "2022-11-20 11:51:45,659 [INFO ]  vis_save_dir:./weights/train_VFIformerSmall/vis\n",
            "INFO:root:snapshot_save_dir:./weights/train_VFIformerSmall/snapshot\n",
            "2022-11-20 11:51:45,659 [INFO ]  snapshot_save_dir:./weights/train_VFIformerSmall/snapshot\n",
            "INFO:root:----- generator parameters: 17.024426 -----\n",
            "2022-11-20 11:51:49,892 [INFO ]  ----- generator parameters: 17.024426 -----\n",
            "INFO:root:init criterion and optimizer...\n",
            "2022-11-20 11:51:49,892 [INFO ]  init criterion and optimizer...\n",
            "INFO:root:  using l1 loss...\n",
            "2022-11-20 11:51:49,894 [INFO ]    using l1 loss...\n",
            "INFO:root:  using flow loss...\n",
            "2022-11-20 11:51:49,894 [INFO ]    using flow loss...\n",
            "INFO:root:  using ter loss...\n",
            "2022-11-20 11:51:49,894 [INFO ]    using ter loss...\n",
            "INFO:root:training on  ...VimeoDataset\n",
            "2022-11-20 11:51:49,895 [INFO ]  training on  ...VimeoDataset\n",
            "INFO:root:173 training samples\n",
            "2022-11-20 11:51:49,895 [INFO ]  173 training samples\n",
            "INFO:root:the init lr: 0.000100\n",
            "2022-11-20 11:51:49,895 [INFO ]  the init lr: 0.000100\n",
            "Traceback (most recent call last):\n",
            "  File \"train.py\", line 152, in <module>\n",
            "    main()\n",
            "  File \"train.py\", line 149, in main\n",
            "    trainer.train()\n",
            "  File \"/content/drive/MyDrive/Duong/VFIformer/code/models/trainer.py\", line 194, in train\n",
            "    output, flow_list = self.net(img0, img1, None)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/parallel/distributed.py\", line 705, in forward\n",
            "    output = self.module(*inputs[0], **kwargs[0])\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/content/drive/MyDrive/Duong/VFIformer/code/models/archs/VFIformer_arch.py\", line 542, in forward\n",
            "    refine_output = self.transformer(x, c0, c1)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/content/drive/MyDrive/Duong/VFIformer/code/models/archs/transformer_layers.py\", line 1001, in forward\n",
            "    fea0 = self.forward_features(s0, self.layers0)\n",
            "  File \"/content/drive/MyDrive/Duong/VFIformer/code/models/archs/transformer_layers.py\", line 989, in forward_features\n",
            "    x = layer(x, x_size)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/content/drive/MyDrive/Duong/VFIformer/code/models/archs/transformer_layers.py\", line 656, in forward\n",
            "    return self.patch_embed(self.conv(self.patch_unembed(self.residual_group(x, x_size), x_size))) + x\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/content/drive/MyDrive/Duong/VFIformer/code/models/archs/transformer_layers.py\", line 595, in forward\n",
            "    x = blk(x, x_size)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/content/drive/MyDrive/Duong/VFIformer/code/models/archs/transformer_layers.py\", line 449, in forward\n",
            "    attn_windows = self.attn(x_windows, x_windows_down, mask_x=self.attn_mask_x, mask_y=self.attn_mask_y)  # nW*B, window_size*window_size, C\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/content/drive/MyDrive/Duong/VFIformer/code/models/archs/transformer_layers.py\", line 251, in forward\n",
            "    x = (attn @ v).transpose(1, 2).reshape(B_, N, C).contiguous()\n",
            "RuntimeError: CUDA out of memory. Tried to allocate 460.00 MiB (GPU 0; 39.59 GiB total capacity; 37.11 GiB already allocated; 398.19 MiB free; 37.31 GiB reserved in total by PyTorch)\n",
            "Killing subprocess 7152\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n",
            "    \"__main__\", mod_spec)\n",
            "  File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/distributed/launch.py\", line 340, in <module>\n",
            "    main()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/distributed/launch.py\", line 326, in main\n",
            "    sigkill_handler(signal.SIGTERM, None)  # not coming back\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/distributed/launch.py\", line 301, in sigkill_handler\n",
            "    raise subprocess.CalledProcessError(returncode=last_return_code, cmd=cmd)\n",
            "subprocess.CalledProcessError: Command '['/usr/bin/python3', '-u', 'train.py', '--local_rank=0', '--launcher', 'pytorch', '--gpu_ids', '0', '--loss_l1', '--loss_ter', '--loss_flow', '--use_tb_logger', '--batch_size', '24', '--net_name', 'VFIformerSmall', '--name', 'train_VFIformerSmall', '--max_iter', '300', '--crop_size', '192', '--save_epoch_freq', '5', '--data_root', '/content/drive/My Drive/Duong/datasets/smallest', '--num_workers', '2']' returned non-zero exit status 1.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python test.py --data_root \"/content/drive/My Drive/datasets/vimeo_triplet\" --testset VimeoDataset --net_name VFIformerSmall \\\n",
        "  --resume \"/content/drive/My Drive/VFIformer/weights/train_VFIformerSmall/snapshot/net_105.pth\" \\\n",
        "  --save_result --save_folder \"/content/drive/My Drive/datasets/vimeo_triplet/test_results\""
      ],
      "metadata": {
        "id": "1XN_-G6gHhHk",
        "outputId": "25b5369d-9055-499e-d6ab-651c839e0d64",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Disabled distributed training.\n",
            "2022-08-15 16:15:12,339 [INFO ]  Logging file is /content/drive/My Drive/datasets/vimeo_triplet/test_results/test_vfiformer/20220815_161512.log\n",
            "2022-08-15 16:15:12,339 [INFO ]  random_seed:0\n",
            "2022-08-15 16:15:12,340 [INFO ]  name:test_vfiformer\n",
            "2022-08-15 16:15:12,340 [INFO ]  phase:test\n",
            "2022-08-15 16:15:12,340 [INFO ]  gpu_ids:[0]\n",
            "2022-08-15 16:15:12,340 [INFO ]  launcher:none\n",
            "2022-08-15 16:15:12,340 [INFO ]  local_rank:0\n",
            "2022-08-15 16:15:12,340 [INFO ]  net_name:VFIformerSmall\n",
            "2022-08-15 16:15:12,340 [INFO ]  data_root:/content/drive/My Drive/datasets/vimeo_triplet\n",
            "2022-08-15 16:15:12,340 [INFO ]  trainset:VimeoDataset\n",
            "2022-08-15 16:15:12,341 [INFO ]  testset:VimeoDataset\n",
            "2022-08-15 16:15:12,341 [INFO ]  crop_size:192\n",
            "2022-08-15 16:15:12,341 [INFO ]  batch_size:1\n",
            "2022-08-15 16:15:12,341 [INFO ]  num_workers:4\n",
            "2022-08-15 16:15:12,341 [INFO ]  data_augmentation:False\n",
            "2022-08-15 16:15:12,341 [INFO ]  resume:/content/drive/My Drive/VFIformer/weights/train_VFIformerSmall/snapshot/net_105.pth\n",
            "2022-08-15 16:15:12,341 [INFO ]  resume_flownet:\n",
            "2022-08-15 16:15:12,341 [INFO ]  save_folder:/content/drive/My Drive/datasets/vimeo_triplet/test_results/test_vfiformer\n",
            "2022-08-15 16:15:12,341 [INFO ]  save_result:True\n",
            "2022-08-15 16:15:12,342 [INFO ]  dist:False\n",
            "2022-08-15 16:15:12,342 [INFO ]  rank:-1\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3503: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  \"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "2022-08-15 16:15:16,511 [INFO ]  ----- generator parameters: 17.024426 -----\n",
            "2022-08-15 16:15:16,517 [INFO ]  start testing...\n",
            "2022-08-15 16:15:16,517 [INFO ]  20 testing samples\n",
            "2022-08-15 16:15:19,690 [INFO ]  testing on: 00001/0001    psnr: 20.373328    ssim: 0.697932\n",
            "2022-08-15 16:15:20,428 [INFO ]  testing on: 00001/0002    psnr: 20.429682    ssim: 0.700806\n",
            "2022-08-15 16:15:21,188 [INFO ]  testing on: 00001/0003    psnr: 20.484634    ssim: 0.704268\n",
            "2022-08-15 16:15:21,905 [INFO ]  testing on: 00001/0004    psnr: 19.075170    ssim: 0.568258\n",
            "2022-08-15 16:15:22,625 [INFO ]  testing on: 00001/0005    psnr: 20.149826    ssim: 0.630112\n",
            "2022-08-15 16:15:23,353 [INFO ]  testing on: 00001/0006    psnr: 20.811068    ssim: 0.661224\n",
            "2022-08-15 16:15:24,072 [INFO ]  testing on: 00001/0007    psnr: 20.052586    ssim: 0.610983\n",
            "2022-08-15 16:15:24,791 [INFO ]  testing on: 00001/0008    psnr: 19.442653    ssim: 0.575973\n",
            "2022-08-15 16:15:25,515 [INFO ]  testing on: 00001/0009    psnr: 19.007357    ssim: 0.548806\n",
            "2022-08-15 16:15:26,262 [INFO ]  testing on: 00001/0010    psnr: 18.629936    ssim: 0.526344\n",
            "2022-08-15 16:15:26,983 [INFO ]  testing on: 00001/0011    psnr: 18.440923    ssim: 0.515653\n",
            "2022-08-15 16:15:27,707 [INFO ]  testing on: 00001/0012    psnr: 18.301578    ssim: 0.507408\n",
            "2022-08-15 16:15:28,423 [INFO ]  testing on: 00001/0013    psnr: 18.276738    ssim: 0.503915\n",
            "2022-08-15 16:15:29,132 [INFO ]  testing on: 00001/0014    psnr: 18.598399    ssim: 0.520811\n",
            "2022-08-15 16:15:29,847 [INFO ]  testing on: 00001/0015    psnr: 19.017759    ssim: 0.541669\n",
            "2022-08-15 16:15:30,581 [INFO ]  testing on: 00001/0016    psnr: 19.466106    ssim: 0.563200\n",
            "2022-08-15 16:15:31,303 [INFO ]  testing on: 00001/0017    psnr: 19.005264    ssim: 0.572232\n",
            "2022-08-15 16:15:32,021 [INFO ]  testing on: 00001/0018    psnr: 18.823476    ssim: 0.557886\n",
            "2022-08-15 16:15:32,733 [INFO ]  testing on: 00001/0019    psnr: 18.918367    ssim: 0.553478\n",
            "2022-08-15 16:15:33,458 [INFO ]  testing on: 00001/0020    psnr: 19.158276    ssim: 0.556573\n",
            "2022-08-15 16:15:33,742 [INFO ]  --------- average PSNR: 19.323156,  SSIM: 0.580877\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xX_jMGHVObxZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "\n",
        "data_root = '/content/drive/My Drive/datasets/vimeo_triplet' \n",
        "data_list = open(os.path.join(data_root, 'tri_testlist.txt'), 'r')\n",
        "flow_data = []\n",
        "for item in data_list:\n",
        "  name = str(item).strip()\n",
        "  flow = sorted(glob.glob(os.path.join(data_root.replace('vimeo_triplet', ''), 'flows', name, '*.npy')))\n",
        "  print(glob.glob(os.path.join(data_root.replace('vimeo_triplet', ''), 'flows',name, '*.npy')))\n",
        "print(flow_data)\n",
        "\n",
        "# print(glob.glob(f'/content/drive/My Drive/datasets/**/*'))"
      ],
      "metadata": {
        "id": "xA_Y_oDnNbif",
        "outputId": "abcafec7-df2f-4cb3-c477-79254ad35dd1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['/content/drive/My Drive/datasets/flows/00001/0001/flo21.npy', '/content/drive/My Drive/datasets/flows/00001/0001/flo23.npy']\n",
            "['/content/drive/My Drive/datasets/flows/00001/0002/flo23.npy', '/content/drive/My Drive/datasets/flows/00001/0002/flo21.npy']\n",
            "['/content/drive/My Drive/datasets/flows/00001/0003/flo21.npy', '/content/drive/My Drive/datasets/flows/00001/0003/flo23.npy']\n",
            "['/content/drive/My Drive/datasets/flows/00001/0004/flo23.npy', '/content/drive/My Drive/datasets/flows/00001/0004/flo21.npy']\n",
            "['/content/drive/My Drive/datasets/flows/00001/0005/flo21.npy', '/content/drive/My Drive/datasets/flows/00001/0005/flo23.npy']\n",
            "['/content/drive/My Drive/datasets/flows/00001/0006/flo23.npy', '/content/drive/My Drive/datasets/flows/00001/0006/flo21.npy']\n",
            "['/content/drive/My Drive/datasets/flows/00001/0007/flo23.npy', '/content/drive/My Drive/datasets/flows/00001/0007/flo21.npy']\n",
            "['/content/drive/My Drive/datasets/flows/00001/0008/flo23.npy', '/content/drive/My Drive/datasets/flows/00001/0008/flo21.npy']\n",
            "['/content/drive/My Drive/datasets/flows/00001/0009/flo21.npy', '/content/drive/My Drive/datasets/flows/00001/0009/flo23.npy']\n",
            "['/content/drive/My Drive/datasets/flows/00001/0010/flo23.npy', '/content/drive/My Drive/datasets/flows/00001/0010/flo21.npy']\n",
            "['/content/drive/My Drive/datasets/flows/00001/0011/flo23.npy', '/content/drive/My Drive/datasets/flows/00001/0011/flo21.npy']\n",
            "['/content/drive/My Drive/datasets/flows/00001/0012/flo23.npy', '/content/drive/My Drive/datasets/flows/00001/0012/flo21.npy']\n",
            "['/content/drive/My Drive/datasets/flows/00001/0013/flo23.npy', '/content/drive/My Drive/datasets/flows/00001/0013/flo21.npy']\n",
            "['/content/drive/My Drive/datasets/flows/00001/0014/flo21.npy', '/content/drive/My Drive/datasets/flows/00001/0014/flo23.npy']\n",
            "['/content/drive/My Drive/datasets/flows/00001/0015/flo21.npy', '/content/drive/My Drive/datasets/flows/00001/0015/flo23.npy']\n",
            "['/content/drive/My Drive/datasets/flows/00001/0016/flo21.npy', '/content/drive/My Drive/datasets/flows/00001/0016/flo23.npy']\n",
            "['/content/drive/My Drive/datasets/flows/00001/0017/flo23.npy', '/content/drive/My Drive/datasets/flows/00001/0017/flo21.npy']\n",
            "['/content/drive/My Drive/datasets/flows/00001/0018/flo23.npy', '/content/drive/My Drive/datasets/flows/00001/0018/flo21.npy']\n",
            "['/content/drive/My Drive/datasets/flows/00001/0019/flo21.npy', '/content/drive/My Drive/datasets/flows/00001/0019/flo23.npy']\n",
            "['/content/drive/My Drive/datasets/flows/00001/0020/flo23.npy', '/content/drive/My Drive/datasets/flows/00001/0020/flo21.npy']\n",
            "[]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "VFIFormer.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "gpuClass": "premium",
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}